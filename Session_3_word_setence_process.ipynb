{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CEAI 1110 Deep Learning in Action: coding action #3\n",
    "\n",
    "Coding activity 3 contains 2 parts:\n",
    "\n",
    "`(1) Build FFNN using Keras API practice\n",
    "(2) Basic language and word&text procecssing `\n",
    "\n",
    "\n",
    "`please kindly refer your coding activity sheet #3 for correspondence`\n",
    "\n",
    "Coach: Yimin Nie\n",
    "\n",
    "email: ymnie888@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk import word_tokenize \n",
    "# stops = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. FFNN continoue--- use Keras to write a simple FFNN \n",
    "\n",
    "`Please compare this code with code in session 2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Code 1.1: load and reshape the mnist data set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784) (60000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "input_dim = 28*28\n",
    "train_X = train_X.reshape(len(train_X),input_dim)/255.0\n",
    "test_X = test_X.reshape(len(test_X),input_dim)/255.0\n",
    "train_y = pd.get_dummies(train_y).values\n",
    "test_y = pd.get_dummies(test_y).values\n",
    "print(train_X.shape,test_X.shape,train_y.shape,test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784) (12000, 784)\n"
     ]
    }
   ],
   "source": [
    "# split some data as validation data set\n",
    "train_X,valid_X,train_y,valid_y = train_test_split(train_X,train_y,shuffle=True,random_state=2019,test_size=0.2)\n",
    "print(train_X.shape,valid_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Code 1.2: build fully connected FFNN using Keras style`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Dense,Dropout,ReLU,PReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras import Model\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "output_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the whole network architecture with fully connected network\n",
    "input_tensor = Input(shape=(input_dim,),name='input',dtype='float32')\n",
    "x = Dense(500,activation='sigmoid')(input_tensor)\n",
    "x = Dense(300,activation='sigmoid')(x)\n",
    "x = Dense(output_dim,activation='softmax')(x)\n",
    "model = Model(inputs=input_tensor, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 545,810\n",
      "Trainable params: 545,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary()) # you can see the summary of your graph model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your callback\n",
    "# a nice Chinese explainaion \n",
    "# https://blog.csdn.net/Einstellung/article/details/83010342\n",
    "\n",
    "callback = [EarlyStopping(monitor='val_loss',patience=2),\n",
    "            ReduceLROnPlateau(patience=1, verbose=0),\n",
    "            ModelCheckpoint('model.h5',save_best_only=True,verbose=0),\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your training parameters\n",
    "epochs = 20\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 17s 346us/step - loss: 0.3772 - acc: 0.8878 - val_loss: 0.2220 - val_acc: 0.9338\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 16s 336us/step - loss: 0.1645 - acc: 0.9503 - val_loss: 0.1480 - val_acc: 0.9547\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 16s 334us/step - loss: 0.1072 - acc: 0.9672 - val_loss: 0.1121 - val_acc: 0.9655\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 16s 339us/step - loss: 0.0739 - acc: 0.9771 - val_loss: 0.1023 - val_acc: 0.9689\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 16s 340us/step - loss: 0.0538 - acc: 0.9832 - val_loss: 0.0918 - val_acc: 0.9718\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 17s 348us/step - loss: 0.0394 - acc: 0.9872 - val_loss: 0.0900 - val_acc: 0.9730\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 17s 358us/step - loss: 0.0284 - acc: 0.9913 - val_loss: 0.0870 - val_acc: 0.9760\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 17s 361us/step - loss: 0.0217 - acc: 0.9928 - val_loss: 0.0870 - val_acc: 0.9770\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 17s 353us/step - loss: 0.0075 - acc: 0.9983 - val_loss: 0.0792 - val_acc: 0.9792\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 17s 344us/step - loss: 0.0057 - acc: 0.9989 - val_loss: 0.0783 - val_acc: 0.9792\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 17s 345us/step - loss: 0.0047 - acc: 0.9991 - val_loss: 0.0783 - val_acc: 0.9793\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 15s 320us/step - loss: 0.0035 - acc: 0.9994 - val_loss: 0.0783 - val_acc: 0.9795\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 17s 361us/step - loss: 0.0034 - acc: 0.9995 - val_loss: 0.0783 - val_acc: 0.9795\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 16s 342us/step - loss: 0.0034 - acc: 0.9995 - val_loss: 0.0783 - val_acc: 0.9795\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 16s 342us/step - loss: 0.0034 - acc: 0.9995 - val_loss: 0.0783 - val_acc: 0.9795\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 17s 345us/step - loss: 0.0034 - acc: 0.9995 - val_loss: 0.0783 - val_acc: 0.9795\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 17s 344us/step - loss: 0.0034 - acc: 0.9995 - val_loss: 0.0783 - val_acc: 0.9795\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 17s 350us/step - loss: 0.0034 - acc: 0.9995 - val_loss: 0.0783 - val_acc: 0.9795\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 17s 353us/step - loss: 0.0034 - acc: 0.9995 - val_loss: 0.0783 - val_acc: 0.9795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16641b9e390>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_X, y=train_y, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=(valid_X, valid_y),\n",
    "          callbacks=callback,\n",
    "          verbose=1\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Code 1.3: Use Dropout techniques to enhance the model performance`\n",
    "\n",
    "`Please compare the differece between this model and previous one`\n",
    "\n",
    "\n",
    "`Reference paper on Dropout by G.Hinton in University of Toronto`\n",
    "\n",
    "http://jmlr.org/papers/v15/srivastava14a.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the whole network architecture with fully connected network\n",
    "input_tensor = Input(shape=(input_dim,),name='input',dtype='float32')\n",
    "x = Dense(500,activation='sigmoid')(input_tensor)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(300,activation='sigmoid')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(output_dim,activation='softmax')(x)\n",
    "model = Model(inputs=input_tensor, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 18s 377us/step - loss: 0.4518 - acc: 0.8624 - val_loss: 0.2320 - val_acc: 0.9310\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 18s 366us/step - loss: 0.2054 - acc: 0.9384 - val_loss: 0.1598 - val_acc: 0.9521\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 18s 365us/step - loss: 0.1468 - acc: 0.9555 - val_loss: 0.1238 - val_acc: 0.9638\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 18s 370us/step - loss: 0.1104 - acc: 0.9657 - val_loss: 0.1106 - val_acc: 0.9654\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 18s 372us/step - loss: 0.0913 - acc: 0.9706 - val_loss: 0.0899 - val_acc: 0.9725\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 19s 387us/step - loss: 0.0738 - acc: 0.9761 - val_loss: 0.0868 - val_acc: 0.9732\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 18s 376us/step - loss: 0.0636 - acc: 0.9790 - val_loss: 0.0799 - val_acc: 0.9759\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 18s 378us/step - loss: 0.0544 - acc: 0.9828 - val_loss: 0.0765 - val_acc: 0.9768\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 18s 381us/step - loss: 0.0468 - acc: 0.9852 - val_loss: 0.0774 - val_acc: 0.9783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x166440e6dd8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = [EarlyStopping(monitor='val_loss',patience=1),\n",
    "            ReduceLROnPlateau(patience=1, verbose=0),\n",
    "            ModelCheckpoint('model.h5',save_best_only=True,verbose=0),\n",
    "            ]\n",
    "\n",
    "model.fit(x=train_X, y=train_y, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=(valid_X, valid_y),\n",
    "          callbacks=callback,\n",
    "          verbose=1\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Code 1.4: Use Relu and PRelu as activation and observe the performance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 18s 378us/step - loss: 0.2625 - acc: 0.9198 - val_loss: 0.1200 - val_acc: 0.9617\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 18s 372us/step - loss: 0.1307 - acc: 0.9599 - val_loss: 0.1159 - val_acc: 0.9675\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 18s 367us/step - loss: 0.1008 - acc: 0.9687 - val_loss: 0.0873 - val_acc: 0.9728\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 17s 363us/step - loss: 0.0842 - acc: 0.9746 - val_loss: 0.0961 - val_acc: 0.9729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x166440e6278>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = Input(shape=(input_dim,),name='input',dtype='float32')\n",
    "x = Dense(500,activation='relu')(input_tensor)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(300,activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(output_dim,activation='softmax')(x)\n",
    "model = Model(inputs=input_tensor, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-3), metrics=['accuracy'])\n",
    "\n",
    "callback = [EarlyStopping(monitor='val_loss',patience=1),\n",
    "            ReduceLROnPlateau(patience=1, verbose=0),\n",
    "            ModelCheckpoint('model.h5',save_best_only=True,verbose=0),\n",
    "            ]\n",
    "\n",
    "model.fit(x=train_X, y=train_y, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=(valid_X, valid_y),\n",
    "          callbacks=callback,\n",
    "          verbose=1\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Code practice for words&text processing basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Code 2.1`\n",
    "\n",
    "1. Basic text and sentence cleaning\n",
    "2. Build lookup table and tokens for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"question_answer_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87599, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           question  \\\n",
       "0           1  To whom did the Virgin Mary allegedly appear i...   \n",
       "1           2  What is in front of the Notre Dame Main Building?   \n",
       "2           3  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3           4                  What is the Grotto at Notre Dame?   \n",
       "4           5  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                    answer  \n",
       "0               Saint Bernadette Soubirous  \n",
       "1                a copper statue of Christ  \n",
       "2                        the Main Building  \n",
       "3  a Marian place of prayer and reflection  \n",
       "4       a golden statue of the Virgin Mary  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', 'question', 'answer'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cols= train.columns.values\n",
    "all_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(all_cols[0],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                    answer  \n",
       "0               Saint Bernadette Soubirous  \n",
       "1                a copper statue of Christ  \n",
       "2                        the Main Building  \n",
       "3  a Marian place of prayer and reflection  \n",
       "4       a golden statue of the Virgin Mary  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Code 2.2`\n",
    "\n",
    "make all words lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure all rows are string and no mixed type\n",
    "train['question'] = train['question'].fillna('unknown').astype(str)\n",
    "train['answer'] = train['answer'].fillna('unkown').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['question'] = train['question'].apply(lambda x:x.lower() if x else \"\")\n",
    "train['answer'] = train['answer'].apply(lambda x:x.lower() if x else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to whom did the virgin mary allegedly appear i...</td>\n",
       "      <td>saint bernadette soubirous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is in front of the notre dame main building?</td>\n",
       "      <td>a copper statue of christ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the basilica of the sacred heart at notre dame...</td>\n",
       "      <td>the main building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is the grotto at notre dame?</td>\n",
       "      <td>a marian place of prayer and reflection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what sits on top of the main building at notre...</td>\n",
       "      <td>a golden statue of the virgin mary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  to whom did the virgin mary allegedly appear i...   \n",
       "1  what is in front of the notre dame main building?   \n",
       "2  the basilica of the sacred heart at notre dame...   \n",
       "3                  what is the grotto at notre dame?   \n",
       "4  what sits on top of the main building at notre...   \n",
       "\n",
       "                                    answer  \n",
       "0               saint bernadette soubirous  \n",
       "1                a copper statue of christ  \n",
       "2                        the main building  \n",
       "3  a marian place of prayer and reflection  \n",
       "4       a golden statue of the virgin mary  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = np.concatenate([train['question'].values,train['answer'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Code 2.3`\n",
    "\n",
    "use keras tokenizer API to tokenize all text in this data set, and build a word_index (lookup table)\n",
    "\n",
    "exercice: write a function to realize your own dictionary first\n",
    "\n",
    "Hint: regular expression to filter our punctuation first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(list(all_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tokenizer.word_index  # this is lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2572"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['virgin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['unkown'] = len(dt)+1\n",
    "dt['flag'] = len(dt)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`small exercise`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a word list: v = [\"I\",\"like\",\"this\",\"book\"]\n",
    "\n",
    "build you own dictionary with index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': 0, 'like': 1, 'this': 2, 'book': 3}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict = {}\n",
    "v = [\"I\",\"like\",\"this\",\"book\"]\n",
    "n=0\n",
    "for word in v:\n",
    "    if word not in my_dict.keys():\n",
    "        my_dict[word] = n\n",
    "    n+=1\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict['like']=len(my_dict)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': 0, 'like': 5, 'this': 2, 'book': 3}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Code 2.4`\n",
    "\n",
    "Use toknizer to fit text and convert all text to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = tokenizer.texts_to_sequences(train['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original sentence at row 0:{}\n",
      "----------------------------------------------------------------------\n",
      "to whom did the virgin mary allegedly appear in 1858 in lourdes france?\n",
      "====================================================================================================\n",
      "vector of this sentence after using index table\n",
      "----------------------------------------------------------------------\n",
      "[5, 307, 8, 1, 2572, 662, 7352, 813, 4, 5622, 4, 18207, 186]\n"
     ]
    }
   ],
   "source": [
    "print(\"original sentence at row 0:{}\")\n",
    "print(\"-\"*70)\n",
    "print(train.iloc[0]['question'])\n",
    "print(\"=\"*100)\n",
    "print(\"vector of this sentence after using index table\")\n",
    "print(\"-\"*70)\n",
    "print(train_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original sentence at row 0:{}\n",
      "----------------------------------------------------------------------\n",
      "what is the grotto at notre dame?\n",
      "====================================================================================================\n",
      "vector of this sentence after using index table\n",
      "----------------------------------------------------------------------\n",
      "[2, 7, 1, 22780, 33, 531, 524]\n"
     ]
    }
   ],
   "source": [
    "print(\"original sentence at row 0:{}\")\n",
    "print(\"-\"*70)\n",
    "print(train.iloc[3]['question'])\n",
    "print(\"=\"*100)\n",
    "print(\"vector of this sentence after using index table\")\n",
    "print(\"-\"*70)\n",
    "print(train_X[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Code 1.5`\n",
    "\n",
    "Use keras API to make all input vectors the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pad_sequences(train_X, maxlen=maxlen,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original sentence at row 0:{}\n",
      "----------------------------------------------------------------------\n",
      "to whom did the virgin mary allegedly appear in 1858 in lourdes france?\n",
      "====================================================================================================\n",
      "vector of this sentence after using index table\n",
      "----------------------------------------------------------------------\n",
      "[    4  5622     4 18207   186     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0]\n"
     ]
    }
   ],
   "source": [
    "print(\"original sentence at row 0:{}\")\n",
    "print(\"-\"*70)\n",
    "print(train.iloc[0]['question'])\n",
    "print(\"=\"*100)\n",
    "print(\"vector of this sentence after using index table\")\n",
    "print(\"-\"*70)\n",
    "print(train_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
